{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import namedtuple\n",
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import join as join_path, exists as file_exists, realpath, expanduser, basename, splitext\n",
    "\n",
    "import pandas as pd\n",
    "from bokeh.models import HoverTool, CDSView, BooleanFilter\n",
    "from bokeh.plotting import figure, ColumnDataSource\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.resources import INLINE\n",
    "from bokeh.io import output_notebook, show\n",
    "\n",
    "from classifiers import bucket_alist\n",
    "from colors import from_file as color_from_file\n",
    "from images import from_file as image_from_file, NeuralNetwork\n",
    "\n",
    "output_notebook(resources=INLINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket_to_dict(bucketed_list):\n",
    "    result = {}\n",
    "    for i, (_, classes) in enumerate(sorted(bucketed_list)):\n",
    "        for cls in classes:\n",
    "            result[cls] = i\n",
    "    return result\n",
    "\n",
    "OldLabelData = namedtuple('OldLabelData', [\n",
    "    'old_class',\n",
    "    'old_label',\n",
    "    'old_label_size',\n",
    "    'label_true_positive_init',\n",
    "    'label_true_positive_update',\n",
    "])\n",
    "\n",
    "TRIAL_COLUMNS = [\n",
    "    # trial information\n",
    "    'trial_id',\n",
    "    'mean_regret',\n",
    "    'mean_regret_scaled',\n",
    "    'true_positive_init',\n",
    "    'true_positive_update',\n",
    "    # old label information\n",
    "    'old_class',\n",
    "    'old_label',\n",
    "    'old_label_size',\n",
    "    'label_true_positive_init',\n",
    "    'label_true_positive_update',\n",
    "    # new label information\n",
    "    'new_class',\n",
    "    'new_label',\n",
    "    'label_mean_regret',\n",
    "    'label_max_regret',\n",
    "    'label_mean_regret_scaled',\n",
    "    # ranking information\n",
    "    'heuristic',\n",
    "    'heuristic_rank',\n",
    "    'misclassification',\n",
    "    'misclassification_rank',\n",
    "]\n",
    "\n",
    "TrialRow = namedtuple('TrialRow', TRIAL_COLUMNS)\n",
    "\n",
    "\n",
    "def trial_to_dataframe(trial):\n",
    "    # trial information\n",
    "    trial_id = trial.get_persistent_id()\n",
    "    mean_regret = trial.mean_regret()\n",
    "    mean_regret_scaled = trial.mean_regret_scaled()\n",
    "    true_positive_init = trial.true_positive_init()\n",
    "    true_positive_update = trial.true_positive_update()\n",
    "    # pre-calculate duplicated old label information\n",
    "    old_label_data = {}\n",
    "    for old_class in trial.old_ys():\n",
    "        old_label_data[old_class] = OldLabelData(\n",
    "            old_class=old_class,\n",
    "            old_label=trial.domain_utils.class_to_label(old_class),\n",
    "            old_label_size=sum(trial.load_summary()[old_class].values()),\n",
    "            label_true_positive_init=trial.label_true_positive_init(old_class),\n",
    "            label_true_positive_update=trial.label_true_positive_update(old_class),\n",
    "        )\n",
    "    # loop through new labels and create dataframe rows\n",
    "    trial_df_rows = []\n",
    "    for new_class in trial.new_ys():\n",
    "        # new class information\n",
    "        new_class = new_class\n",
    "        new_label = trial.domain_utils.class_to_label(new_class)\n",
    "        label_mean_regret = trial.label_mean_regret(new_class)\n",
    "        label_max_regret = trial.label_max_regret(new_class)\n",
    "        label_mean_regret_scaled = trial.label_mean_regret_scaled(new_class)\n",
    "        # ranking information\n",
    "        misclassifications = dict(trial.label_misclassification_order(new_class))\n",
    "        heuristics = dict(trial.label_distance_order(new_class))\n",
    "        misclassification_ranks = bucket_to_dict(bucket_alist(misclassifications))\n",
    "        heuristic_ranks = bucket_to_dict(bucket_alist(heuristics))\n",
    "        # cross old labels and calculate heuristic information\n",
    "        for old_class in old_label_data.keys():\n",
    "            trial_df_rows.append(TrialRow(\n",
    "                # trial information\n",
    "                trial_id=trial_id,\n",
    "                mean_regret=mean_regret,\n",
    "                mean_regret_scaled=mean_regret_scaled,\n",
    "                true_positive_init=true_positive_init,\n",
    "                true_positive_update=true_positive_update,\n",
    "                # old label information\n",
    "                old_class=old_class,\n",
    "                old_label=old_label_data[old_class].old_label,\n",
    "                old_label_size=old_label_data[old_class].old_label_size,\n",
    "                label_true_positive_init=old_label_data[old_class].label_true_positive_init,\n",
    "                label_true_positive_update=old_label_data[old_class].label_true_positive_update,\n",
    "                # new label information\n",
    "                new_class=new_class,\n",
    "                new_label=new_label,\n",
    "                label_mean_regret=label_mean_regret,\n",
    "                label_max_regret=label_max_regret,\n",
    "                label_mean_regret_scaled=label_mean_regret_scaled,\n",
    "                # ranking information\n",
    "                heuristic=heuristic_ranks[old_class],\n",
    "                heuristic_rank=heuristics[old_class],\n",
    "                misclassification=misclassifications[old_class],\n",
    "                misclassification_rank=misclassification_ranks[old_class],\n",
    "            ))\n",
    "    return pd.DataFrame(trial_df_rows, columns=TRIAL_COLUMNS)\n",
    "\n",
    "\n",
    "def create_tribulation(directory):\n",
    "    \"\"\"Convert a collection of trials (a \"tribulation\") to a dataframe.\n",
    "\n",
    "    Since what we are interested in is how the new classes are distributed\n",
    "    among the old classes, each trial will contribute:\n",
    "\n",
    "        |old_labels| * |new_labels|\n",
    "\n",
    "    rows to the final dataframe. To make plotting easier, some information will\n",
    "    be duplicated amongst these rows. In addition to trial-level data (which\n",
    "    will be the same for all rows from a trial, information specific to the old\n",
    "    label (label true positive rate at both the initialization and update\n",
    "    stages) and to the new label (the mean and max regret) will also be\n",
    "    duplicated.\n",
    "    \"\"\"\n",
    "    directory = realpath(expanduser(directory))\n",
    "    tribulation_file = join_path(directory, basename(directory) + '.tribulation')\n",
    "    if file_exists(tribulation_file):\n",
    "        return pd.read_csv(tribulation_file)\n",
    "    if basename(directory).startswith('color'):\n",
    "        from_file = color_from_file\n",
    "    elif basename(directory).startswith('cifar'):\n",
    "        from_file = image_from_file\n",
    "    else:\n",
    "        raise ValueError('Cannot determine domain for directory {}'.format(directory))\n",
    "    trial_dfs = {}\n",
    "    for i, filename in enumerate(listdir(directory)):\n",
    "        trial_id = splitext(filename)[0]\n",
    "        if len(trial_id.split('_')) != 2:\n",
    "            continue\n",
    "        if trial_id in trial_dfs:\n",
    "            continue\n",
    "        print(i, datetime.now().isoformat(), trial_id)\n",
    "        trial_df_file = join_path(directory, trial_id + '.trial_df')\n",
    "        if file_exists(trial_df_file):\n",
    "            trial_df = pd.read_csv(trial_df_file)\n",
    "        else:\n",
    "            trial = from_file(join_path(directory, filename))\n",
    "            trial_df = trial_to_dataframe(trial)\n",
    "            trial_df.to_csv(trial_df_file, index=False)\n",
    "        trial_dfs[trial_id] = trial_df\n",
    "    tribulation_df = pd.concat(trial_dfs.values())\n",
    "    tribulation_df.to_csv(tribulation_file, index=False)\n",
    "    return tribulation_df\n",
    "\n",
    "def create_color_tribulation(directory):\n",
    "    df = create_tribulation(directory)\n",
    "    regex = 'colors(?P<num_centroids>[0-9]*)_'\n",
    "    regex += 's(?P<random_seed>[0-9.]*)'\n",
    "    regex += 'n(?P<dataset_size>[0-9]*)'\n",
    "    regex += 'k(?P<num_colors>[0-9]*)'\n",
    "    df['regex'] = df['trial_id'].apply(\n",
    "        lambda s: re.match(regex, s)\n",
    "    )\n",
    "    for attr in ['random_seed', 'num_centroids', 'dataset_size', 'num_colors']:\n",
    "        df[attr] = df['regex'].apply(lambda match: match.group(attr))\n",
    "        if attr != 'random_seed':\n",
    "            df[attr] = df[attr].astype(int)\n",
    "    del df['regex']\n",
    "    return df\n",
    "\n",
    "def create_image_tribulation(directory):\n",
    "    from images import NeuralNetwork\n",
    "    df = create_tribulation(directory)\n",
    "    df['neural_network'] = df['trial_id'].apply(\n",
    "        lambda s: NeuralNetwork(join_path(directory, s.split('_')[0] + '.hdf5'))\n",
    "    )\n",
    "    df['int_labels'] = df['neural_network'].apply(lambda nn: nn.int_labels)\n",
    "    df['batch_size'] = df['neural_network'].apply(lambda nn: nn.batch_size)\n",
    "    df['num_epochs'] = df['neural_network'].apply(lambda nn: nn.num_epochs)\n",
    "    del df['neural_network']\n",
    "    return df\n",
    "\n",
    "def plot_tribulation_roc(source):\n",
    "    roc_fig = figure(\n",
    "        width=400, height=400,\n",
    "        x_axis_label='Proportion of All Data Searched',\n",
    "        y_axis_label='Proportion of Label Data Found',\n",
    "        tools=['box_select'],\n",
    "    )\n",
    "    roc_fig.line(\n",
    "        x='searched',\n",
    "        y='found',\n",
    "        selection_color='red',\n",
    "        source=source,\n",
    "    )\n",
    "    return roc_fig\n",
    "\n",
    "def plot_tribulation_regret(source):\n",
    "    if not isinstance(source, ColumnDataSource):\n",
    "        source = ColumnDataSource(source)\n",
    "    regret_fig = figure(\n",
    "        width=400, height=400,\n",
    "        x_range=[0, 1.1],\n",
    "        x_axis_label='Classifier Test Accuracy',\n",
    "        y_range=[0, 1.1],\n",
    "        y_axis_label='Regret (lower is better)',\n",
    "        tools=['box_select'],\n",
    "    )\n",
    "    renderer = regret_fig.x(\n",
    "        x='true_positive_init',\n",
    "        y='mean_regret_scaled',\n",
    "        selection_color='red',\n",
    "        source=source,\n",
    "    )\n",
    "    regret_fig.add_tools(HoverTool(renderers=[renderer], tooltips=[\n",
    "        ('trial', '@trial_id'),\n",
    "        ('accuracy', '@true_positive_init'),\n",
    "        ('regret', '@mean_regret_scaled'),\n",
    "    ]))\n",
    "    return regret_fig\n",
    "\n",
    "def plot_tribulation(df):\n",
    "    source = ColumnDataSource(df)\n",
    "    roc_fig = plot_tribulation_roc(source)\n",
    "    regret_fig = plot_tribulation_regret(source)\n",
    "    figures = [roc_fig, regret_fig]\n",
    "    return gridplot([figures])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_color_tribulation('colors').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Regret\n",
    "\n",
    "    grid of\n",
    "        num_centroids: 10, 20, 50, 100\n",
    "        num_new_labels: 20, 50, 100, 200\n",
    "        with the constraint that num_colors > num_centroids\n",
    "    num_colors: 1000, 10000, 100000, 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_color_regret():\n",
    "    # load data\n",
    "    df = create_color_tribulation('colors')\n",
    "    # group by independent variables\n",
    "    plot_df = df[[\n",
    "        'trial_id',\n",
    "        'random_seed', 'num_centroids', 'dataset_size', 'num_colors',\n",
    "        'mean_regret_scaled',\n",
    "    ]].drop_duplicates().groupby([\n",
    "        'num_centroids', 'dataset_size', 'num_colors'\n",
    "    ]).mean()['mean_regret_scaled'].reset_index()\n",
    "\n",
    "    plot_df.shape\n",
    "    plot_df['num_centroids'] = plot_df['num_centroids'].astype(int)\n",
    "    plot_df['dataset_size'] = plot_df['dataset_size'].astype(int)\n",
    "    plot_df['num_colors'] = plot_df['num_colors'].astype(int)\n",
    "    # build grid plot\n",
    "    grid = []\n",
    "    source = ColumnDataSource(plot_df)\n",
    "    for r, num_centroids in enumerate(reversed([10, 20, 50, 100])):\n",
    "        row = []\n",
    "        for c, num_new_labels in enumerate([20, 50, 100, 200]):\n",
    "            if num_new_labels <= num_centroids:\n",
    "                row.append(None)\n",
    "                continue\n",
    "            fig = figure(\n",
    "                width=200, height=200,\n",
    "                title='{} + {} = {}'.format(num_centroids, num_new_labels - num_centroids, num_new_labels),\n",
    "                x_axis_type='log',\n",
    "                x_range=[90, 1100000],\n",
    "                y_range=[0, 0.025],\n",
    "            )\n",
    "            fig.x(\n",
    "                x='dataset_size',\n",
    "                y='mean_regret_scaled',\n",
    "                source=source,\n",
    "                view=CDSView(\n",
    "                    source=source,\n",
    "                    filters=[BooleanFilter(plot_df.apply(\n",
    "                        (lambda row: (row['num_centroids'] == num_centroids) & (row['num_colors'] == num_new_labels)),\n",
    "                        axis=1,\n",
    "                    ))],\n",
    "                ),\n",
    "            )\n",
    "            row.append(fig)\n",
    "        grid.append(row)\n",
    "    return gridplot(grid)\n",
    "\n",
    "show(plot_color_regret())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10, Three Labels Complete Sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "create_image_tribulation('cifar10-threes').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(plot_tribulation_regret(create_image_tribulation('cifar10-threes')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-100 Pilot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "create_image_tribulation('cifar100-pilot').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(plot_tribulation_regret(create_image_tribulation('cifar100-pilot')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-100 Orthogonal Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_image_tribulation('cifar100-orthog').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_cifar100_orthog():\n",
    "    tribulation = create_image_tribulation('cifar100-orthog')\n",
    "    labels = list(range(5, 30, 5))\n",
    "    epochs = list(range(200, 800, 200))\n",
    "    # sort the trials\n",
    "    networks = {}\n",
    "    for trial_id in tribulation['trial_id'].unique():\n",
    "        classifier_str = trial_id.split('_')[0]\n",
    "        path = join_path('cifar100-orthog', classifier_str + '.hdf5')\n",
    "        nn = NeuralNetwork(path)\n",
    "        key = (len(nn.int_labels), nn.num_epochs)\n",
    "        networks.setdefault(key, set()).add(trial_id)\n",
    "\n",
    "\n",
    "    default_labels = 10\n",
    "    default_epoch = 200\n",
    "\n",
    "    label_plots = []\n",
    "    for num_labels in sorted(labels):\n",
    "        key = (num_labels, default_epoch)\n",
    "        plot_df = tribulation[tribulation['trial_id'].apply(\n",
    "            lambda s: any(s.startswith(prefix) for prefix in networks[key])\n",
    "        )]\n",
    "        label_plots.append(plot_tribulation_regret(plot_df))\n",
    "    show(gridplot([label_plots]))\n",
    "\n",
    "    epoch_plots = []\n",
    "    for num_epochs in sorted(epochs):\n",
    "        key = (default_labels, num_epochs)\n",
    "        plot_df = tribulation[tribulation['trial_id'].apply(\n",
    "            lambda s: any(s.startswith(prefix) for prefix in networks[key])\n",
    "        )]\n",
    "        epoch_plots.append(plot_tribulation_regret(plot_df))\n",
    "    show(gridplot([epoch_plots]))\n",
    "\n",
    "plot_cifar100_orthog()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
