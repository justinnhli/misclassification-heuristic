{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from itertools import accumulate\n",
    "from os import listdir\n",
    "from os.path import splitext, join as join_path, exists as file_exists\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bokeh.models import HoverTool, CDSView, BooleanFilter\n",
    "from bokeh.plotting import figure, ColumnDataSource\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.resources import INLINE\n",
    "from bokeh.io import output_notebook, show\n",
    "\n",
    "from classifiers import RegretTrial\n",
    "from colors import from_file as colors_from_file\n",
    "from images import ImageUtils, NeuralNetwork, ImageDataset\n",
    "\n",
    "output_notebook(resources=INLINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_constant_list(value, size):\n",
    "    return size * [value]\n",
    "\n",
    "\n",
    "def trials_to_dataframe(trials):\n",
    "    return pd.DataFrame({\n",
    "        'trial_label': [trial.get_persistent_id() for trial in trials],\n",
    "        'regret': [trial.mean_regret() for trial in trials],\n",
    "        'accuracy': [trial.mean_accuracy() for trial in trials],\n",
    "    })\n",
    "\n",
    "\n",
    "def trials_to_label_dataframe(trials):\n",
    "    data = []\n",
    "    for trial in trials:\n",
    "        summary = trial.load_summary()\n",
    "        dataset_size = sum(sum(summary[old_label].values()) for old_label in trial.old_ys())\n",
    "        for new_label in trial.new_ys():\n",
    "            new_label_size = sum(misclass_dict.get(new_label, 0) for misclass_dict in summary.values())\n",
    "            searched = [0] + list(accumulate(\n",
    "                [\n",
    "                    sum(summary[old_label].values()) / dataset_size\n",
    "                    for old_label, _ in trial.label_distance_order(new_label)\n",
    "                ],\n",
    "                operator.add\n",
    "            ))\n",
    "            found = [0] + list(accumulate(\n",
    "                [\n",
    "                    summary[old_label].get(new_label, 0) / new_label_size \n",
    "                    for old_label, _ in trial.label_distance_order(new_label)\n",
    "                ],\n",
    "                operator.add\n",
    "            ))\n",
    "            persistent_id = len(found) * [trial.get_persistent_id()]\n",
    "            data.extend(zip(persistent_id, searched, found))\n",
    "    return pd.DataFrame(data, columns=['trial_label', 'searched', 'found'])\n",
    "\n",
    "\n",
    "def trials_to_dataframe_all(trials):\n",
    "    trial_dfs = []\n",
    "    for trial in trials:\n",
    "        summary = trial.load_summary()\n",
    "        dataset_size = sum(sum(summary.get(old_label, {}).values()) for old_label in trial.old_ys())\n",
    "        persistent_id = trial.get_persistent_id()\n",
    "        label_dfs = []\n",
    "        for new_label in trial.new_ys():\n",
    "            new_label_size = sum(misclass_dict.get(new_label, 0) for misclass_dict in summary.values())\n",
    "            distance_order = [old_label for old_label, _ in trial.label_distance_order(new_label)]\n",
    "            # calculate the cumulative sums first\n",
    "            searched = [0] + list(accumulate(\n",
    "                [sum(summary.get(old_label, {}).values()) / dataset_size for old_label in distance_order],\n",
    "                operator.add,\n",
    "            ))\n",
    "            found = [0] + list(accumulate(\n",
    "                [summary.get(old_label, {}).get(new_label, 0) / new_label_size for old_label in distance_order],\n",
    "                operator.add,\n",
    "            ))\n",
    "            # calculate other non-constant columns\n",
    "            order = list(range(len(found)))\n",
    "            old_labels = [np.nan] + distance_order\n",
    "            accuracy = [np.nan] + [trial.label_accuracy(old_label) for old_label in distance_order]\n",
    "            # create label dataframe\n",
    "            label_df = pd.DataFrame(\n",
    "                list(zip(\n",
    "                    order, \n",
    "                    old_labels, \n",
    "                    searched, found,\n",
    "                    accuracy,\n",
    "                )),\n",
    "                columns=['order', 'old_label', 'searched', 'found', 'label_accuracy'],\n",
    "            )\n",
    "            # calculate constant columns\n",
    "            label_df['trial_label'] = persistent_id\n",
    "            label_df['new_labels'] = new_label\n",
    "            label_df['label_mean_regret'] = trial.label_mean_regret(new_label)\n",
    "            label_df['label_max_regret'] = trial.label_max_regret(new_label)\n",
    "            # add dataframe to list\n",
    "            label_dfs.append(label_df)\n",
    "        # calculate trial-level data\n",
    "        trial_df = pd.concat(label_dfs)\n",
    "        trial_df['trial_mean_regret'] = trial_df['label_mean_regret'].mean()\n",
    "        trial_df['trial_mean_accuracy'] = trial_df['label_accuracy'].mean()\n",
    "        # add to dataframes\n",
    "        trial_dfs.append(trial_df)\n",
    "    return pd.concat(trial_dfs)\n",
    "\n",
    "\n",
    "def create_image_tribulation(directory, dataset_str):\n",
    "    assert dataset_str in ['cifar10', 'cifar100']\n",
    "    df_filename = 'tribulations/' + '_'.join([directory, dataset_str]) + '.csv'\n",
    "    if file_exists(df_filename):\n",
    "        return pd.read_csv(df_filename)\n",
    "    else:\n",
    "        utils = ImageUtils(dataset_str)\n",
    "        dataset = ImageDataset(dataset_str)\n",
    "        trials = []\n",
    "        for filename in sorted(set(f for f in listdir(directory))):\n",
    "            if not filename.endswith('hdf5'):\n",
    "                continue\n",
    "            path = join_path(directory, filename)\n",
    "            print(path)\n",
    "            classifier = NeuralNetwork(path)\n",
    "            regret_trial = RegretTrial(classifier, utils, dataset, path_prefix=directory)\n",
    "            trials.append(regret_trial)\n",
    "        df = trials_to_dataframe_all(trials)\n",
    "        df.to_csv(df_filename)\n",
    "        return df\n",
    "\n",
    "\n",
    "def plot_tribulation(df):\n",
    "    source = ColumnDataSource(df)\n",
    "    tools = ['box_select']\n",
    "    roc_fig = figure(\n",
    "        width=400, height=400,\n",
    "        title='CIFAR 100 Pilot',\n",
    "        x_axis_label='Proportion of All Data Searched',\n",
    "        y_axis_label='Proportion of Label Data Found',\n",
    "        tools=tools,\n",
    "    )\n",
    "    for trial in df['trial_label'].unique():\n",
    "        roc_fig.line(\n",
    "            x='searched', \n",
    "            y='found',\n",
    "            selection_color='red',\n",
    "            source=source,\n",
    "            view=CDSView(\n",
    "                source=source,\n",
    "                filters=[\n",
    "                    BooleanFilter([label == trial for label in source.data['trial_label']]),\n",
    "                ],\n",
    "            ),\n",
    "        )\n",
    "    regret_fig = figure(\n",
    "        width=400, height=400,\n",
    "        title='CIFAR 100 Pilot Trials',\n",
    "        x_axis_label='Classifier Test Accuracy',\n",
    "        y_axis_label='Absolute Regret (lower is better)',\n",
    "        tools=tools,\n",
    "    )\n",
    "    renderer = regret_fig.x(\n",
    "        x='trial_mean_accuracy',\n",
    "        y='trial_mean_regret',\n",
    "        selection_color='red',\n",
    "        source=source,\n",
    "    )\n",
    "    regret_fig.add_tools(HoverTool(renderers=[renderer], tooltips=[\n",
    "        ('trial', '@trial_label'),\n",
    "        ('accuracy', '@trial_mean_accuracy'),\n",
    "        ('regret', '@trial_mean_regret'),\n",
    "    ]))\n",
    "    figures = [roc_fig, regret_fig]\n",
    "    show(gridplot([figures]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10, Three Labels Complete Sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_image_tribulation('cifar-10', 'cifar10').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tribulation(create_image_tribulation('cifar-10', 'cifar10'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-100 Pilot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "create_image_tribulation('cifar-100-pilot', 'cifar100').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tribulation(create_image_tribulation('cifar-100-pilot', 'cifar100'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-100 Orthogonal Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_image_tribulation('cifar-100-orthog', 'cifar100').head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
